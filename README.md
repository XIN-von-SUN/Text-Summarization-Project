# Text-Summarization-Project
seq2seq-Encoder-Decoder-Attention-TextSummarization

1. Build a very basic seq2seq based abstractive summarization system by initially word to index word2vec embeddings;

2. Add attention mechanism to build an attention based seq2seq model for abstractive summarization by initially word to index word2vec embeddings;

3. Used pre-trained word embeddings on Wiki corpus to build an attention based seq2seq model for abstractive summarization.
